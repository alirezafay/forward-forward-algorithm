{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":6856,"status":"ok","timestamp":1700339294189,"user":{"displayName":"alireza fayyazi","userId":"15383343501144298006"},"user_tz":-210},"id":"h7rnPNj_AInc"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torchvision.datasets import MNIST\n","from torchvision.transforms import Compose, ToTensor, Lambda\n","from torch.optim import Adam, SGD\n","from torch.utils.data import DataLoader\n","import numpy as np\n","import random\n","from skimage.filters import gaussian\n","from sklearn.preprocessing import OneHotEncoder"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":325,"status":"ok","timestamp":1700333739986,"user":{"displayName":"alireza fayyazi","userId":"15383343501144298006"},"user_tz":-210},"id":"8P-HIixPHyZO"},"outputs":[],"source":["# در این بخش داده هارا نرمالیزه میکنیم . و فلت میکنیم و آنها را به تنسور تبدیل میکنیم. بچ هایی که تعریف کردیم به سایز کل دیتاست ما هستند و تمامی دادگان دیتاست را یکجا پردازش میکنیم. \n","def Dataloader():\n","    def normalize_data(x):\n","\n","        x_min = torch.min(x, dim=1, keepdim=True)[0]\n","        x_max = torch.max(x, dim=1, keepdim=True)[0]\n","        x_norm = torch.sub(x, x_min)\n","        x_norm = torch.div(x_norm, x_max - x_min)\n","        x_ = torch.flatten(x)\n","        return x_\n","\n","    transform = Compose([ToTensor(),Lambda(normalize_data)])\n","\n","    train_loader = DataLoader(MNIST('./data/', train=True,download=True,transform=transform),batch_size=50000, shuffle=True)\n","    test_loader = DataLoader(MNIST('./data/', train=False,download=True,transform=transform),batch_size=10000, shuffle=False)\n","    x, y = next(iter(train_loader))\n","    x, y = x.cuda(), y.cuda()\n","    x_test, y_test = next(iter(test_loader))\n","    x_test, y_test = x_test.cuda(), y_test.cuda()\n","    return x,y,x_test,y_test"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1700333741578,"user":{"displayName":"alireza fayyazi","userId":"15383343501144298006"},"user_tz":-210},"id":"W2ccTtf9H3nb"},"outputs":[],"source":["# در اینجا تولید ماسک دادگان و تولید تصویر هیبرید را در یک تابع انجام میدهیم. \n","import torchvision.transforms as transforms\n","transfrom_tensor = transforms.ToTensor()\n","def data_gen(x,batch_size):\n","    random_image = np.random.randint(2, size=(28,28)).astype(np.float32)\n","    random_image = gaussian(random_image, sigma=2.5)\n","    # ابتدا یک تصویر ردنوم به سایز تصویر ورودی تولید میکنیم و با انخاب یک آستانه ی مناسب، ماسک شامل صفر و یک از تصویر رندوم تولید شده را درست میکنیم. \n","    mask = (random_image > 0.5).astype(np.float32)\n","    mask = torch.from_numpy(mask)\n","    flattened_mask = mask.view(-1)\n","    expanded_mask = flattened_mask.expand(x.size(0), -1).to('cuda')\n","    x = x.to('cuda')\n","    hybrid_img = x*expanded_mask + x[torch.randperm(x.size(0))] * (1-expanded_mask)\n","    return hybrid_img\n"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":140777,"status":"ok","timestamp":1700335427381,"user":{"displayName":"alireza fayyazi","userId":"15383343501144298006"},"user_tz":-210},"id":"ujg_k8J0LYth"},"outputs":[],"source":["class AFNet(torch.nn.Module):\n","# یک شبکه ی سه لایه مخفی تعریف میکنیم که سایز ورودی آن به ابعاد تصویر فلت شده است. \n","    def __init__(self):\n","        super().__init__()\n","        self.layers = []\n","        self.layers.append (Layer(784, 600).cuda())\n","        self.layers.append (Layer(600, 400).cuda())\n","        self.layers.append (Layer(400, 300).cuda())\n","# با توجه به شبکه ای که تعریف کردیم و کلاس لایه ای که جداگانه تعریف کردیم، بخش آموزش شبکه، ورودی های منفی و مثبت را دریافت میکند و با استفاده از کلاس بعدی آنهارا آموزش میدهید.\n","    def train(self, positive_data, negative_data):\n","        out_positive, out_negative = positive_data, negative_data\n","        for layer in self.layers:\n","            out_positive, out_negative = layer.train(out_positive, out_negative)\n","# در اینجا بخش پیش بینی شبکه آورده شده است. اینجا خروجی هر لایه از شبکه در یک لیست ریخته میشود که خروجی هر لایه تبدیل ووردی آن به یک بردار نمایش دیگر از ورودی است که به طبقه بند ما داده می شود.\n","    def predict(self, x):\n","        out_layer = x\n","        out_layers = torch.Tensor([]).cuda()\n","        for layer in self.layers:\n","            out_layer = layer(out_layer)\n","            out_layers = torch.cat([out_layers,out_layer],1)\n","        return out_layers\n","# از آنجایی که در این روش ما با هر لایه و آموزش تابع هزینه ی محلی آن سر و کار داریم، یک کلاس لایه ی جداگانه تعریف میشود. که خروجی را به صورت لایه به لایه تولید میکند و به کلاس شبکه ی اصلی میدهد. \n","class Layer(nn.Linear):\n","    def __init__(self, in_features, out_features,bias=True):\n","        super().__init__(in_features, out_features, bias)\n","        self.relu = torch.nn.ReLU()\n","        self.optimizer = Adam(self.parameters(), lr=0.05)\n","\n","    def forward(self, x):\n","        x_norm = torch.nn.functional.normalize(x, p=2, dim=1, eps=1e-5)\n","        x_out = self.relu(torch.mm(x_norm, self.weight.T) +self.bias.unsqueeze(0))\n","        return x_out\n","# در بخش آموزش شبکه با توجه به معیار خوب بودنی که تعریف میشود، و آستانه ای که انتخاب میکنیم، شبکه سعی میکند فعالیت بخش دادگان مثبت را تا جای امکان بالا نگه دارد و در مورد دادگان منفی، برعکس عمل میکند. \n","# در نهایت هم بعد از آموزش ایپاک های مورد نظر، ورودی از لایه ی مورد نظر رد میشود و به بخش آموزش شبکه ی اصلی داده میشود. \n","    def train(self, x_positive, x_negative):\n","        num_epochs = 1000\n","        threshold = 2.0\n","        for i in range(num_epochs):\n","            loss = torch.log(1 + torch.exp(torch.cat([ threshold-(self.forward(x_positive).pow(2).mean(1)),(self.forward(x_negative).pow(2).mean(1))-threshold]))).mean()\n","            self.optimizer.zero_grad()\n","            loss.backward()\n","            self.optimizer.step()\n","        out_layer_pos = self.forward(x_positive)\n","        out_layer_neg = self.forward(x_negative)\n","        return out_layer_pos.detach(),out_layer_neg.detach()\n","\n","torch.manual_seed(1234)\n","x_train,y_train,x_test,y_test = Dataloader()\n","x_negative_train = data_gen(x_train,50000)\n","net = AFNet()\n","net.train(x_train, x_negative_train)\n","\n","\n"]},{"cell_type":"code","execution_count":55,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1700339250271,"user":{"displayName":"alireza fayyazi","userId":"15383343501144298006"},"user_tz":-210},"id":"MecjcRXFyUUf"},"outputs":[],"source":["# این تابع برای تبدیل برچسب های داده ی امنیست، به یک بردار وان هات است که در ادامه مرود استفاده قرار میگیرد و با برچسب های تولیدی توسط طبقه بند مقایسه میشود. \n","def one_hot(y):\n","    y = y.to('cpu')\n","    y = y.long()\n","    one_hot_y = torch.nn.functional.one_hot(y, num_classes=10)\n","    return one_hot_y.to(torch.float32)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cq0CDuAlUZwz","outputId":"64afb13a-2ce2-46d2-dd73-70bcfa1b3360"},"outputs":[{"name":"stdout","output_type":"stream","text":["loss tensor(2.8166, device='cuda:0', grad_fn=<DivBackward1>)\n","loss tensor(2.3351, device='cuda:0', grad_fn=<DivBackward1>)\n","loss tensor(1.0440, device='cuda:0', grad_fn=<DivBackward1>)\n","loss tensor(0.5028, device='cuda:0', grad_fn=<DivBackward1>)\n","loss tensor(0.2872, device='cuda:0', grad_fn=<DivBackward1>)\n","loss tensor(0.1895, device='cuda:0', grad_fn=<DivBackward1>)\n"]}],"source":["class LinearClassifier(nn.Module):\n","    def __init__(self, input_dimension):\n","        super().__init__()\n","        self.softmax = nn.Softmax(dim=1)\n","        self.linear = torch.nn.Linear(input_dimension, 10).cuda()\n","        self.optimizer = Adam(self.parameters(), lr=0.05)\n","        self.criteria = nn.CrossEntropyLoss()\n","# در اینجا بخش پیشبینی طبقه بند، خروجی های به هم پوست شده ی شبکه ی قبلی را میگیرد و از یک لایه ی خطی عبور میدهد و به سافتمکس میدهد تا برچسب هر داده با بیشترین احتمال وقوع تخمین زده شود. \n","    def predict(self,x):\n","        represent_vector = net.predict(x)\n","        y_h = self.forward(represent_vector)\n","        soft_out = self.softmax(y_h)\n","        return soft_out.argmax(1)\n","\n","    def forward(self,x):\n","        return self.linear(x)\n","# در بخش آموزش شبکه هم از معیار آنتروپی استفاده شده است که برچسب های وان هات شده را با برچسب های تولید شده از ادغام شبکه ی قبلی با طبقه بند مقایسه میکند و سعی میکند این اختلاف را به خداقل برساند. \n","    def train(self, x,y):\n","        num_epochs = 300\n","        for i in range (num_epochs):\n","            y_onehot = one_hot(y).cuda()\n","            represent_vector = net.predict(x)\n","            y_transformed = self.forward(represent_vector)\n","            loss = self.criteria(y_transformed,y_onehot)\n","            self.optimizer.zero_grad()\n","            loss.backward()\n","            self.optimizer.step()\n","            if i % 30 == 0:\n","                print('loss', loss)\n","input_dimension = 300+400+600\n","torch.manual_seed(1234)\n","classifier = LinearClassifier(input_dimension)\n","classifier.train(x_train,y_train)\n","\n","\n"]},{"cell_type":"code","execution_count":52,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":528,"status":"ok","timestamp":1700338971609,"user":{"displayName":"alireza fayyazi","userId":"15383343501144298006"},"user_tz":-210},"id":"WirS0feX1_J3","outputId":"3e506dbb-a0ff-4efe-8119-461dab1dc7be"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train Accuracy 0.9589\n"]}],"source":["y_pred_train = classifier.predict(x_train)\n","y_true_train = y_train.to('cpu')\n","y_pred_train = y_pred_train.to('cpu')\n","train_accuracy = torch.sum(y_pred_train == y_true_train).item() / len(y_train)\n","print('Train Accuracy' , train_accuracy)"]},{"cell_type":"code","execution_count":53,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":335,"status":"ok","timestamp":1700338976044,"user":{"displayName":"alireza fayyazi","userId":"15383343501144298006"},"user_tz":-210},"id":"Tbm0UHPO0t6r","outputId":"04f7f81c-5315-4874-b997-35dd949bbba2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test Accuracy 0.9372\n"]}],"source":["y_test_t = y_test.to('cpu')\n","y_pred_te = classifier.predict(x_test)\n","y_pred_t = y_pred_te.to('cpu')\n","test_accuracy = torch.sum(y_pred_t == y_test_t).item() / len(y_test)\n","print('Test Accuracy',test_accuracy)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyO3QseZjDRcWlnp0EQyT/oF","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
