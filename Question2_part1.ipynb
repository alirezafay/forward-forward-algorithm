{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plmPq4ZYm0xe",
        "outputId": "0b099eb2-4895-4997-d0c0-8e1321f670a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train error: 0.08424001932144165\n",
            "Test error: 0.08310002088546753\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "from torch.optim import Adam\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import Compose, ToTensor, Normalize, Lambda\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def one_hot_encoding(x, y):\n",
        "    # در اینجا از ورودی یک کپی میسازیم و بر حسب اندیس های بردار برچسب هایمان، ورودی را مقدار دهی مکنیم و در 10 درایه ی اول ماتریس ورودی به صورت وان هات جایگذاری میکنیم.\n",
        "    x_hat = x.clone()\n",
        "    x_hat[range(x.shape[0]), y] = x.max()\n",
        "    return x_hat\n",
        "# در این بخش داده هارا نرمالیزه میکنیم . و فلت میکنیم و آنها را به تنسور تبدیل میکنیم. بچ هایی که تعریف کردیم به سایز کل دیتاست ما هستند و تمامی دادگان دیتاست را یکجا پردازش میکنیم.\n",
        "# دادگان مثبت و منفی را نیز در این تابع تولید مکنیم. دادگان مثبت را با برچسب های درست و دادگان منفی را با استفاده از برچسب های غلط تولید میکنیم.\n",
        "def Dataloader():\n",
        "    def normalize_data(x):\n",
        "\n",
        "        x_min = torch.min(x, dim=1, keepdim=True)[0]\n",
        "        x_max = torch.max(x, dim=1, keepdim=True)[0]\n",
        "        x_norm = torch.sub(x, x_min)\n",
        "        x_norm = torch.div(x_norm, x_max - x_min)\n",
        "        x_ = torch.flatten(x)\n",
        "        return x_\n",
        "\n",
        "    transform = Compose([ToTensor(),Lambda(normalize_data)])\n",
        "\n",
        "    train_loader = DataLoader(MNIST('./data/', train=True,download=True,transform=transform),batch_size=50000, shuffle=True)\n",
        "    test_loader = DataLoader(MNIST('./data/', train=False,download=True,transform=transform),batch_size=10000, shuffle=False)\n",
        "    x, y = next(iter(train_loader))\n",
        "    x, y = x.cuda(), y.cuda()\n",
        "    x_test, y_test = next(iter(test_loader))\n",
        "    x_test, y_test = x_test.cuda(), y_test.cuda()\n",
        "    x_positive = one_hot_encoding(x, y)\n",
        "    x_negative = one_hot_encoding(x, y[torch.randperm(x.size(0))])\n",
        "    return x,y,x_test,y_test,x_positive,x_negative\n",
        "\n",
        "class AFNet(torch.nn.Module):\n",
        "# یک شبکه ی سه لایه مخفی تعریف میکنیم که سایز ورودی آن به ابعاد تصویر فلت شده است.\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layers = []\n",
        "        self.layers.append (Layer(784, 600).cuda())\n",
        "        self.layers.append (Layer(600, 400).cuda())\n",
        "        self.layers.append (Layer(400, 300).cuda())\n",
        "# با توجه به شبکه ای که تعریف کردیم و کلاس لایه ای که جداگانه تعریف کردیم، بخش آموزش شبکه، ورودی های منفی و مثبت را دریافت میکند و با استفاده از کلاس بعدی آنهارا آموزش میدهید.\n",
        "\n",
        "    def train(self, positive_data, negative_data):\n",
        "        out_positive, out_negative = positive_data, negative_data\n",
        "        for layer in self.layers:\n",
        "            out_positive, out_negative = layer.train(out_positive, out_negative)\n",
        "# در اینجا دو لیست تعریف میکنیم که یکی برای معیار خوب بودن در هر لایه است و یکی معیار خوب بودن در نهایت برای هر برچسب است.\n",
        "    def predict(self, x,y):\n",
        "        g_label = []\n",
        "        unique_labels = torch.unique(y)\n",
        "        label_num = len(unique_labels)\n",
        "        for label in range(label_num):\n",
        "            data_gen = one_hot_encoding(x, label)\n",
        "            g_layer = []\n",
        "            for layer in self.layers:\n",
        "                data_gen = layer(data_gen).pow(2)\n",
        "                g_layer += [data_gen.mean(1)]\n",
        "            g_label += [sum(g_layer).unsqueeze(1)]\n",
        "        g_label = torch.cat(g_label, 1)\n",
        "        label_predict = g_label.argmax(1)\n",
        "        return label_predict\n",
        "# از آنجایی که در این روش ما با هر لایه و آموزش تابع هزینه ی محلی آن سر و کار داریم، یک کلاس لایه ی جداگانه تعریف میشود. که خروجی را به صورت لایه به لایه تولید میکند و به کلاس شبکه ی اصلی میدهد.\n",
        "\n",
        "class Layer(nn.Linear):\n",
        "    def __init__(self, in_features, out_features,bias=True):\n",
        "        super().__init__(in_features, out_features, bias)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.optimizer = Adam(self.parameters(), lr=0.05)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_norm = torch.nn.functional.normalize(x, p=2, dim=1, eps=1e-5)\n",
        "        x_out = self.relu(torch.mm(x_norm, self.weight.T) +self.bias.unsqueeze(0))\n",
        "        return x_out\n",
        "# در بخش آموزش شبکه با توجه به معیار خوب بودنی که تعریف میشود، و آستانه ای که انتخاب میکنیم، شبکه سعی میکند فعالیت بخش دادگان مثبت را تا جای امکان بالا نگه دارد و در مورد دادگان منفی، برعکس عمل میکند.\n",
        "# در نهایت هم بعد از آموزش ایپاک های مورد نظر، ورودی از لایه ی مورد نظر رد میشود و به بخش آموزش شبکه ی اصلی داده میشود.\n",
        "    def train(self, x_positive, x_negative):\n",
        "        num_epochs = 1000\n",
        "        threshold = 2.0\n",
        "        for i in range(num_epochs):\n",
        "            loss = torch.log(1 + torch.exp(torch.cat([ threshold-(self.forward(x_positive).pow(2).mean(1)),(self.forward(x_negative).pow(2).mean(1))-threshold]))).mean()\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "        out_layer_pos = self.forward(x_positive)\n",
        "        out_layer_neg = self.forward(x_negative)\n",
        "        return out_layer_pos.detach(),out_layer_neg.detach()\n",
        "\n",
        "torch.manual_seed(1234)\n",
        "x_train,y_train,x_test,y_test,positive_data,negative_data = Dataloader()\n",
        "net = AFNet()\n",
        "net.train(positive_data, negative_data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = net.predict(x_test, y_test)\n",
        "accuracy_test = (predictions == y_test).sum().item()/len(y_test)"
      ],
      "metadata": {
        "id": "jt99yocJm9oq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m12gLyLouUCa",
        "outputId": "2dc30de2-43e4-47c6-f072-a0604d225e6c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9169"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = net.predict(x_train, y_train)\n",
        "accuracy_train = (predictions == y_train).sum().item()/len(y_train)"
      ],
      "metadata": {
        "id": "oRi4RRnzuVRJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8B0GFu9ujRJ",
        "outputId": "352830f3-36fc-44c8-97aa-1753f535bbe8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.91576"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jI3wQmb0uo8t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}